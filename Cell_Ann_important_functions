#####
##### important functions #####
#####

##### load files and pass it to a new object ######
##### these files are saved by save() function ####

loadRData <- function(fileName){
#loads an RData file, and returns it
    load(fileName)
    get(ls()[ls() != "fileName"])
}

#####
##### a dataframe to a matrix 
##### the first column of df should be GENE 
##### then GENE become the rownames of the output matrix
#####

df_to_mat <- function(df){
	rowN = df$GENE
	##
	mat = as.matrix(df[,-1])
	##
	rownames(mat) = rowN
	##
	return(mat)
}


################ make the 2 matrix equal !!! ##############
################ input is the log matrix !!! ###########

equal_matrix <- function(query_mat,ref_mat){
	##########
	genes_overlap = rownames(query_mat)[which(rownames(query_mat) %in% rownames(ref_mat) == T)]
	########## head(rownames(query_mat2))
	m = match(genes_overlap,rownames(query_mat))
	query_mat2 = query_mat[m,]
	########## head(rownames(ref_mat2))
	m = match(genes_overlap,rownames(ref_mat))
	ref_mat2 = ref_mat[m,]
	########## OK !!!! Then normalize !!!! ########
	##########
	ref_mat_input3 = exp(ref_mat2)-1
	#print(head(colSums(ref_mat_input3)))
	query_mat_input3 = exp(query_mat2)-1
	#print(colSums(query_mat_input3))
	##########
	combined_mat = cbind(query_mat_input3,ref_mat_input3)
	#######
	combined_mat_norm = limma::normalizeBetweenArrays(combined_mat,method="quantile")
	combined_mat_norm = log(combined_mat_norm+1)
	combined_mat_norm = round(combined_mat_norm,2)
	#######
	query_mat_input4 = combined_mat_norm[,1:dim(query_mat_input3)[2]]
	ref_mat_input4 = combined_mat_norm[,-c(1:dim(query_mat_input3)[2])]
	#######
	outputlist = list(query_mat_input4,ref_mat_input4)
	return(outputlist)
}



selection_DEGs <- function(all_used_genes,ref_marker,Top=50){
	#### class(ref_marker) ######
	res = apply(ref_marker,2,function(x) length(which(x %in% all_used_genes == T)))
	num = min(res)
	####
	num_new = min(num,Top)
	#### OK!! Then see the Top genes !!!! #######
	ref_marker_cl = ref_marker[1:num_new,]
	####
	ref_marker_cl = reshape2::melt(as.matrix(ref_marker_cl))
	####
	all_markers = ref_marker_cl$value
	all_markers = all_markers[!duplicated(all_markers)]
	####
	return(all_markers)
}



calculate_Cor <- function(query_mat_input,ref_mat_input,DEGs_overlap){
	k1 = which(DEGs_overlap %in% rownames(query_mat_input) == T)
	k2 = which(DEGs_overlap %in% rownames(ref_mat_input) == T)
	k3 = k1[which(k1 %in% k2 == T)]
	DEGs_overlap = DEGs_overlap[k3]
	######
	query_mat_input_cl = query_mat_input[which(rownames(query_mat_input) %in% DEGs_overlap == T),]
	ref_mat_input_cl = ref_mat_input[which(rownames(ref_mat_input) %in% DEGs_overlap == T),]
	######
	######
	m1 = match(DEGs_overlap,rownames(query_mat_input_cl))
	m2 = match(DEGs_overlap,rownames(ref_mat_input_cl))
	query_mat_input_cl= query_mat_input_cl[m1,]
	ref_mat_input_cl= ref_mat_input_cl[m2,]
	######
	merge_mat = cbind(query_mat_input_cl,ref_mat_input_cl)
	Cor_res <- pcaPP::cor.fk(merge_mat)
	###### split the Cor_res #######
	query_dim = dim(query_mat_input_cl)[2]
	ref_dim = dim(ref_mat_input_cl)[2]
	######
	Cor_res = Cor_res[,-c(1:query_dim)]
	Cor_res = Cor_res[c(1:query_dim),]
	###### Then we output the most largest clusters ########
	return(Cor_res)
}


Analysis_cor <- function(cor_res,lower_cutoff = 0.4){
	####
	# lower_cutoff = 0.35
	###### print the max of cor_res ######
	print(apply(cor_res,1,max))
	######
	cor_resv = as.vector(cor_res)
	cor_resv = sort(cor_resv,decreasing=T)
	######
	model <- mclust::densityMclust(cor_resv,G=1:3)
	###### First we need to know how many models !!!!#########
	number_model = length(levels(as.factor(model$classification)))
	######
	###### Then we get the parameters for each model !!!! ####
	######
	model_mean_total = model$parameters$mean
	model_sd_total = model$parameters$variance$sigmasq
	######
	if(length(model_sd_total) == 1){
		model_sd_total = rep(model_sd_total,number_model)
	}
	###### OK!!! Next we find the cutoffs ########
	if(number_model == 3){
		#### we selected to 2!!! #####
		#### we will find the sencond clusters ####
		tmp_mean = model_mean_total[2]
		tmp_sd = model_sd_total[2]
		cutoff = qnorm(0.75,mean=tmp_mean,sd=sqrt(tmp_sd))
	}
	#######
	if(number_model == 2){
		#### we selected to 2!!! #####
		#### we use the cutoff between the 2 peaks !!!! ##########
		model_classification = as.numeric(model$classification)
		k = which(model$classification %in% model$classification[1] == F)
		index = max(cor_resv[k])
		cutoff = index
	}
	if(number_model == 1){
		#### we selected to 2!!! #####
		#### we use the cutoff between the 2 peaks !!!! ##########
		tmp_mean = model_mean_total[1]
		tmp_sd = model_sd_total[1]
		cutoff = qnorm(0.75,mean=tmp_mean,sd=sqrt(tmp_sd))
	}
	if(cutoff < lower_cutoff){
		cutoff = lower_cutoff
	}
	#####
	return(cutoff)
}


##################

Res_mat_highest_celltype <- function(res_mat,cutoff){
	res_list = list()
	for(i in 1:dim(res_mat)[1]){
		res_mat_tmp = res_mat[i,]
		k = which(res_mat_tmp == max(res_mat_tmp))
		max_cor = res_mat_tmp[k]
		##### #######
		k2 = which(res_mat_tmp <= max_cor & res_mat_tmp >= cutoff)
		if(length(k2) == 0){
			res_mat_tmp_k2 = "Unassigned"
			res_list = c(res_list,list("Unassigned"))
		}
		if(length(k2) > 0){
		##### #######
			res_mat_tmp_k2 = res_mat_tmp[k2]
			res_mat_tmp_k2 = sort(res_mat_tmp_k2,decreasing=T)
			#####
			if(length(res_mat_tmp_k2) >3){
				res_mat_tmp_k2 = res_mat_tmp_k2[1:3]
			}
			res_list = c(res_list,list(names(res_mat_tmp_k2)))
		}
		######
		######
	}
	names(res_list) = rownames(res_mat)
	return(res_list)
}


##########
runDEGs_Ref_sub <- function(Seurat_Obj,method='COSG',idents='celltype',num_of_genes = 100){
	Idents(Seurat_Obj) = idents
	#######
	library(COSG)
	#######
	if(method == 'COSG'){
		marker_cosg <- cosg(
 				Seurat_Obj,
 				groups=c('all'),
 				assay='RNA',
 				slot='data',
 				mu=1,
 				n_genes_user=num_of_genes)
		res = marker_cosg$names
		all_genes = res
	}
	#######
	#######
	return(all_genes)
}


################################
##### This is the functions for CellAnn_scmapcluster ######
##### the input file is the raw counts file ###############

CellAnn_scmapcluster = function(train,
                        test,
                        label_train,
                        threshold = 0.7,
                        time = T){
  start_time = Sys.time()
  ######
  sce = SingleCellExperiment(list(counts = train),colData = data.frame(cell_type1 = label_train))
  logcounts(sce) = log2(counts(sce) + 1)
  rowData(sce)$feature_symbol = rownames(sce)
  sce = selectFeatures(sce)
  ######
  sce_test = SingleCellExperiment(list(counts = test))
  logcounts(sce_test) = log2(counts(sce_test) + 1)
  rowData(sce_test)$feature_symbol = rownames(sce_test)
  ######
  sce = indexCluster(sce)
  scmapCluster_results = scmapCluster(projection = sce_test,index_list = list(sce@metadata$scmap_cluster_index),threshold = threshold)
  predict_label = scmapCluster_results$combined_labs
  #######
  end_time = Sys.time()
  #######
  times = as.numeric(difftime(end_time,start_time,units = 'secs'))
  #######
  if(time){
    return(list(predict_label = predict_label,times = times))
  }
  ########
  return(predict_label)
}



####### get avg mat functions ######

CellAnn_Avg_Mat <- function(data_mat,data_cluster,log='log',scale_factor=10000){
	######
	tag_cluster = unname(data_cluster)
	tag_cluster_level = levels(as.factor(tag_cluster))
	###### normalized back datasets ######
	if(log == 'log'){
		data_mat_exp = exp(data_mat)
		data_mat_exp = data_mat_exp-1
	}
	if(log == 'log2'){
		data_mat_exp = 2^(data_mat)
		data_mat_exp = data_mat_exp-1
	}
	print(paste('Sums:',head(colSums(data_mat_exp[,c(1:2)]))))
	###### data_mat_exp is 1e5 normalize #######
	merge_mat = c()
	for(i in 1:length(tag_cluster_level)){
		index = which(data_cluster %in% tag_cluster_level[i] == T)
		index_mat = data_mat_exp[,index]
		######
		index_sum = rowSums(index_mat)
		######
		merge_mat = c(merge_mat,index_sum)
	}
	###
	merge_mat = matrix(merge_mat,nrow=dim(data_mat)[1])
	###
	rownames(merge_mat) = rownames(data_mat)
	colnames(merge_mat) = tag_cluster_level
	### colSums(merge_mat)
	scale = colSums(merge_mat)/scale_factor
	merge_mat = sweep(merge_mat,2,scale,FUN='/')
	### default norm ####
	merge_mat = round(log(merge_mat+1),5)
	return(merge_mat)
}

###### This function convert cellAnn output #######
###### and compare the results with ground truth ######


Visualize_res <- function(cluster_res,ref_seurat_ct){
	plot_res = list()
	for(i in 1:length(cluster_res)){
		######
		names = names(cluster_res)[i]
		library(stringr)
		query_names = str_extract(names,"(?<=query:)(.+)(?=-->)")
		ref_names = str_extract(names,"(?<=ref:)(.+)")
		print(paste(query_names,ref_names))
		###### load the query ground truth ######
		query_truth_file = paste(query_names,'_test_input_GroundTruthLabel.txt',sep='')
		query_truth = read.table(query_truth_file,sep='\t',header=T)
		###### see the results ######
		query_res = cluster_res[[i]]
		###### merge the table ######
		query_merge = merge(query_res,query_truth)
		###### check ################
		#if(dim(query_merge)[1] == dim(query_res)[1] & dim(query_truth)[1] == dim(query_res)[1]){
		#	print('OK')
		#}else{
		#	print('Error')
		#}
		###### Next calculate the results: ###########
		###### we need to know the reference ct in the datasets #######
		#ref_seurat = loadRData(ref_names)
		#ref_seurat_ct = levels(as.factor(ref_seurat$celltype))
		######
		###### Then calculate the accuracy ############
		plot_res_sub = Class_results(query_merge,ref_seurat_ct[[i]],NDtag='unassigned')
		plot_res = c(plot_res,list(plot_res_sub))
	}
	names(plot_res) = names(cluster_res)
	return(plot_res)
}

#######
####### tag alignment results ##### 
#######

Class_results <- function(query_merge,ref_ct,NDtag='unassigned'){
	####
	res_table = query_merge
	res_table$class1 = 'ND'
	res_table$class2 = 'ND'
	res_table_cl = res_table
	####
	query_res = query_merge$result
	query_truth = query_merge$ground.truth
	####
	for(j in 1:dim(res_table_cl)[1]){
		query_truth_tmp = query_truth[j]
		query_res_tmp = query_res[j]
		if(query_truth_tmp %in% ref_ct == T){
			if(length(grep(" & ",query_res_tmp))==0){
				if(query_res_tmp == query_truth_tmp){
					res_table_cl$class1[j] = 'Correct_Classify'
	 				res_table_cl$class2[j] = 'Correct'
				}
				if(query_res_tmp != query_truth_tmp & query_res_tmp == NDtag){
					res_table_cl$class1[j] = 'Failed_Classify'
	 				res_table_cl$class2[j] = 'Wrong'

				}
				if(query_res_tmp != query_truth_tmp & query_res_tmp != NDtag){
					res_table_cl$class1[j] = 'Wrong_Classify'
	 				res_table_cl$class2[j] = 'Wrong'

				}
			}
			if(length(grep(" & ",query_res_tmp))==1){
				query_res_tmp = unlist(strsplit(query_res_tmp,split=' & '))
				if(query_res_tmp[1] == query_truth_tmp | query_res_tmp[2] == query_truth_tmp){
					res_table_cl$class1[j] = 'Correct_Classify_Half'
	 				res_table_cl$class2[j] = 'Correct'
				}
				if((query_res_tmp[1] != query_truth_tmp) & (query_res_tmp[2] != query_truth_tmp)){
					res_table_cl$class1[j] = 'Wrong_Classify'
	 				res_table_cl$class2[j] = 'Wrong'

				}
			}
			if(length(grep(" & ",query_res_tmp)) > 1){
				query_res_tmp = unlist(strsplit(query_res_tmp,split=' & '))
				if(grep(query_truth_tmp,query_res_tmp) > 0){
					res_table_cl$class1[j] = 'Correct_Classify_Half'
	 				res_table_cl$class2[j] = 'Correct'
				}
				if(grep(query_truth_tmp,query_res_tmp) == 0){
					res_table_cl$class1[j] = 'Wrong_Classify'
	 				res_table_cl$class2[j] = 'Wrong'

				}
			}
		}
		if(query_truth_tmp %in% ref_ct == F){
			if(query_res_tmp != query_truth_tmp & query_res_tmp == NDtag){
				res_table_cl$class1[j] = 'Correct_unClassify'
	 			res_table_cl$class2[j] = 'Correct'
			}
			if(query_res_tmp != query_truth_tmp & query_res_tmp != NDtag){
				res_table_cl$class1[j] = 'Wrong_unClassify'
	 			res_table_cl$class2[j] = 'Wrong'
			}

		}
	}
	return(res_table_cl)
}

#######
##### Next function is Visualize_res_plot #######
#######

####### covert Visualize_res to a plot format ##########
#######

Visualize_res_plot <- function(res_v,tag1="mouse"){
	##### res_v #####
	res_tab = list()
	for(i in 1:length(res_v)){
		#######
		tmp_table = data.frame(class=c('Correct_Classify','Correct_Classify_Half','Failed_Classify','Wrong_Classify','Correct_unClassify','Wrong_unClassify'),counts=0)
		#######
		res_v_sub = res_v[[i]]
		res_v_subSum = data.frame(table(res_v_sub$class1))
		m = match(res_v_subSum$Var1,tmp_table$class)
		tmp_table$counts[m] = res_v_subSum$Freq
		tmp_table$sample = names(res_v)[i]
		res_tab = c(res_tab,list(tmp_table))
	}
	res_tab = do.call('rbind',res_tab)
	if(tag1=="mouse"){
		res_tab$sample2 = gsub('query:Tabula_Muris_mouse_','',res_tab$sample)
		res_tab$sample2 = gsub('ref:Tabula_Muris_mouse_','',res_tab$sample2)
	}
	if(tag1=="H"){
		res_tab$sample2 = gsub('query:','',res_tab$sample)
		res_tab$sample2 = gsub('_seurat_human_pre3','',res_tab$sample2)
		res_tab$sample2 = gsub('ref:','',res_tab$sample2)
	}
	return(res_tab)
}



######## OK next function !!! #######
train = ref_mat_input
test = query_mat_input
label_train = ref_label_input

CellAnn_chetah = function(train,
                  test,
                  label_train,
                  time = F){
  ##########
  library(SingleCellExperiment)
  library(CHETAH)
  ###########
  start_time = Sys.time()
  ###########
  sce = SingleCellExperiment(assays = list(counts = train),colData = data.frame(celltypes = label_train))
  sce_test = SingleCellExperiment(assays = list(counts = test))
  ###########
  sce_test = CHETAHclassifier(input = sce_test, ref_cells = sce)
  ###########
  tmp_tab = sce_test@colData
  ###########
  predict_label = unname(tmp_tab$celltype_CHETAH)
  ########### Then we may found the node !!! ##########
  ### PlotCHETAH(input = sce_test, interm = TRUE)
  nodes = sce_test@int_metadata$CHETAH$nodetypes
  #### 
  k = grep("Node",predict_label)
  #### we change node to cell types ##########
  if(length(k) > 0){
  		for(ki in 1:length(k)){
  			tmp_node = predict_label[k[ki]]
  			tmp_node_index = as.numeric(gsub('Node','',tmp_node)) + 1
  			tmp_ct = names(nodes[[tmp_node_index]])
  			tmp_ct = paste(tmp_ct,collapse=' & ')
  			predict_label[k[ki]] = tmp_ct
  		}
  }
  ############
  end_time = Sys.time()
  ###########
  times = as.numeric(difftime(end_time,start_time,units = 'secs'))
  ###########
  if(time){
    return(list(predict_label = predict_label,times = times))
  }
  return(predict_label)
}


###### Next is the Seurat functions ########

CellAnn_seurat = function(train,
                  test,
                  label_train,
                  k.filter = NA,
                  time = T,
                  selection.method = 'vst',
                  nfeatures = 2000,
                  mean.cutoff = c(0.1, 8),
                  dispersion.cutoff = c(1, Inf),
                  prediction.score.max = 0.5){

  start_time = Sys.time()

  reference = CreateSeuratObject(train)
  reference = NormalizeData(reference,
                            verbose = F)
  reference = FindVariableFeatures(reference,
                                   mean.cutoff = mean.cutoff,
                                   dispersion.cutoff = dispersion.cutoff,
                                   verbose = F)
  reference$celltype = label_train
  query = CreateSeuratObject(test)
  query = NormalizeData(query,
                        verbose = F)
  query = FindVariableFeatures(query,
                               mean.cutoff = mean.cutoff,
                               dispersion.cutoff = dispersion.cutoff,
                               verbose = F)
  k.score=5
  k.anchor=5
  if(dim(query)[2] < 6){
  	k.score= dim(query)[2]-1
  	k.anchor= dim(query)[2]-1
  }
  anchors = FindTransferAnchors(reference,query,k.filter = NA,k.score=k.score,k.anchor = k.anchor)
  k.weight = dim(anchors@anchors)[1]
  if(k.weight > 50){k.weight=50}
  predictions = try(TransferData(anchors,as.character(reference$celltype),k.weight=k.weight))
  while(inherits(predictions,'try-error')){
  	k.weight=k.weight-1
  	print(k.weight)
  	predictions = try(TransferData(anchors,as.character(reference$celltype),k.weight=k.weight))
  }
  query = AddMetaData(query, metadata = predictions)
  ######
  print(summary(query$prediction.score.max))
  ####### query$predicted.id[which(query$prediction.score.max < prediction.score.max)] <- 'ND'
  #######
  predict_label = unname(query$predicted.id)
  ######
  end_time = Sys.time()
  ######
  times = as.numeric(difftime(end_time,start_time,units = 'secs'))
  ######
  if(time){
    return(list(predict_label = predict_label,times = times))
  }
  return(predict_label)
}

####### Next is the scpred methods ########

CellAnn_scpred = function(train,
                  test,
                  label_train,
                  model = 'svmRadial',
                  reclassify = NULL,
                  time = F,
                  threshold = 0.55){

  library(scPred)
  start_time = Sys.time()
  reference = CreateSeuratObject(train)
  query = CreateSeuratObject(test)
  reference = reference %>%
    NormalizeData() %>%
    FindVariableFeatures() %>%
    ScaleData() %>%
    RunPCA() %>%
    RunUMAP(dims = 1:30)
  ###########
  query = NormalizeData(query)
  reference$cell_type = label_train
  reference = getFeatureSpace(reference, "cell_type")
  reference = trainModel(reference,
                         model = model,
                         reclassify = reclassify)
  query = scPredict(query,
                    reference,
                    threshold = threshold)
  predict_label = unname(query$scpred_prediction)
  end_time = Sys.time()
  times = as.numeric(difftime(end_time,start_time,units = 'secs'))
  if(time){
    return(list(predict_label = predict_label,times = times))
  }
  return(predict_label)
}


###########################################
##### Next: CellAnn scClassify ############
###########################################
train = ref_mat_input
test = query_mat_input
label_train = ref_label_input


CellAnn_scClassify <- function(test = test,
                  train = train,
                  label_train = label_train,
                  time=T,
                  prob_threshold=0.5
                  ){
	#### first train the model ####
	####
	scClassify_res_ensemble <- scClassify(exprsMat_train = train,
                                      cellTypes_train = label_train,
                                      exprsMat_test = test,
                                      tree = "HC",
                                      algorithm = "WKNN",
                                      selectFeatures = c("limma"),
                                      similarity = c("pearson", "cosine"),
                                      weighted_ensemble = FALSE,
                                      returnList = FALSE,
                                      verbose = FALSE)
	####
	####
	start_time = Sys.time()
	pred_res <- scClassify_res_ensemble$testRes$test$ensembleRes$cellTypes
	#####
	end_time = Sys.time()
	times = as.numeric(difftime(end_time,start_time,units = 'secs'))
	if(time){
    	return(list(predict_label = pred_res$ensembleRes,times = times))
  	}
	return(pred_res)
}





